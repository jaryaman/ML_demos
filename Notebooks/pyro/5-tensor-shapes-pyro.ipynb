{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor shapes in pyro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [here](https://pytorch.org/docs/master/notes/broadcasting.html) for how broadcasting works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution shapes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest distribution shape is a single univariate distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "from pyro.distributions import Bernoulli, Categorical, Normal, MultivariateNormal\n",
    "from pyro.infer import Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "import pyro.poutine as poutine\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert d.event_shape == ()\n",
    "assert d.batch_shape == ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x.shape == ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.6931)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.log_prob(x)  # the log likelihood of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert d.log_prob(x).shape == ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions can be **batched** by passing in batched parameters. Distributions have two shape attributions\n",
    "- `.batch_shape` = conditionally independent random variables. This can be e.g. the number of IID samples you generate.\n",
    "- `.event_shape` = dependent random variables. E.g. a distribution over scalars has `len(event_shape)==0`, vectors `len(event_shape==1)`, and matrices `len(event_shape==2)`.\n",
    "\n",
    "`.log_prob()` produces a single number for each event, and so has the same shape as `.batch_shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5 * torch.ones(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert d.batch_shape == (3,4)\n",
    "assert d.event_shape == ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to batch distributions is via `.expand()`. Parameters must be identical along the leftmost dimensions (**Todo: don't understand**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Bernoulli(torch.tensor([0.1, 0.2, 0.3, 0.4])).expand([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert d.batch_shape == (3,4)\n",
    "assert d.event_shape == ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x.shape == (3,4)\n",
    "assert d.log_prob(x).shape == (3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Multivariate normal distribution has a non-empty `.event_shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = MultivariateNormal(loc=torch.zeros(3), covariance_matrix=torch.eye(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == (3,)\n",
    "assert len(d.event_shape) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x.shape == (3,)\n",
    "assert d.log_prob(x).shape == ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can treat a univariate distribution as multivariate by calling `to_event(n)` where `n` is the number of batch dimensions (from the right) to declare as *dependent*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Bernoulli(0.5).expand([3,4]).to_event(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert d.batch_shape == (3,)\n",
    "assert d.event_shape == (4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples have shape `batch_shape + event_shape` whereas `.log_prob(x)` has shape `batch_shape`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x.shape == (3,4)\n",
    "assert d.log_prob(x).shape == (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to ensure that `batch_shape` is carefully controlled by either trimming it down with `.to_event` or by declaring dimensions as independent via `pyro.plate`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is always safe to assume dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often in Pyro we'll declare some dimensions as dependent even though they are in fact independent. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pyro.sample(\"x\", Normal(0,1).expand([10]).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x.shape == (10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful because:\n",
    "- It allows us to swap in a higher-dimensional RV later\n",
    "- Allows us to simplify the code because we then don't need a plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyro.plate(\"x_plate\", 10):\n",
    "    x = pyro.sample(\"x\", Normal(0,1))  # .expand([10]) is automatic\n",
    "    assert x.shape == (10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between these two versions is, with `.to_event`, Pyro assumes that the samples are dependent (even though they are actually independent).\n",
    "\n",
    "This is always a safe thing to do -- like for d-separation, it is always safe to assume variables may be dependent, but unsafe to assume independence because this narrows the model class to outside of the true model.\n",
    "\n",
    "In practice, SVI uses reparametrized gradient estimators for `Normal` so, in this case, both gradient estimators have the same performance.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring independent dimensions with `plate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyro.plate` allows you to declare certain **batch** dimensions as independent, allowing inference algorithms to take advantage of this independence. For example, the index of data over a minibatch, is an independent dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plates declare the **rightmost**  batch dimension as independent. Plates can also be nested.\n",
    "```python\n",
    "with pyro.plate(\"x_axis\", 320):\n",
    "    # within this context, batch dimension -1 is independent\n",
    "    with pyro.plate(\"y_axis\", 200):\n",
    "        # within this context, batch dimensions -2 and -1 are independent\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also mix and match plates\n",
    "```python\n",
    "x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "with x_axis:\n",
    "    # within this context, batch dimension -2 is independent\n",
    "with y_axis:\n",
    "    # within this context, batch dimension -3 is independent\n",
    "with x_axis, y_axis:\n",
    "    # within this context, batch dimensions -3 and -2 are independent\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pyro.sample(\"b\", Normal(torch.zeros(2), 1).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert b.shape == (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    a = pyro.sample(\"a\", Normal(0,1))\n",
    "    b = pyro.sample(\"b\", Normal(torch.zeros(2), 1).to_event(1)) \n",
    "    with pyro.plate(\"c_plate\", 2):\n",
    "        c = pyro.sample(\"c\", Normal(torch.zeros(2), 1))  \n",
    "    with pyro.plate(\"d_plate\", 3):\n",
    "        d = pyro.sample(\"d\", Normal(torch.zeros(3,4,5), 1).to_event(2))\n",
    "    \n",
    "    assert a.shape == ()       # batch_shape == ()       event_shape == ()\n",
    "    assert b.shape == (2,)     # batch_shape == ()       event_shape == (2,)\n",
    "    assert c.shape == (2,)     # batch_shape == (2,)     event_shape == ()\n",
    "    assert d.shape == (3,4,5)  # batch_shape == (3,)     event_shape == (4,5)\n",
    "    \n",
    "    #----------------\n",
    "    \n",
    "    x_axis = pyro.plate(\"x_axis\", 3, dim=-2)\n",
    "    y_axis = pyro.plate(\"y_axis\", 2, dim=-3)\n",
    "    with x_axis:\n",
    "        x = pyro.sample(\"x\", Normal(0,1))\n",
    "    with y_axis:\n",
    "        y = pyro.sample(\"y\", Normal(0,1))\n",
    "    with x_axis, y_axis:\n",
    "        xy = pyro.sample(\"xy\", Normal(0,1))\n",
    "        z = pyro.sample(\"z\", Normal(0,1).expand([5]).to_event(1))\n",
    "    \n",
    "    assert x.shape  == (3,1)     # batch_shape == (3,1)  event_shape == ()\n",
    "    assert y.shape  == (2,1,1)   # batch_shape == (2,1,1)  event_shape == ()\n",
    "    assert xy.shape == (2,3,1)  # batch_shape == (2,3,1)  event_shape == ()\n",
    "    assert z.shape  == (2,3,1,5)   # batch_shape == (2,3,1)  event_shape == (5,) <- this one is non-intuitive!!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, guide, loss):\n",
    "    pyro.clear_param_store()\n",
    "    loss.loss(model, guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model1, model1, Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example might also be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1, 1, 1, 1, 5, 6])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_axis = pyro.plate(\"x_axis\", 3, dim=-5)\n",
    "y_axis = pyro.plate(\"y_axis\", 2, dim=-6)\n",
    "with x_axis, y_axis:        \n",
    "    z = pyro.sample(\"z\", Normal(0,1).expand([5,6]).to_event(2))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can programatically observe the shapes of all objects in a model with `trace.format_shapes()`, printing\n",
    "1. The distribution shpae\n",
    "2. The value shape\n",
    "3. The log probability shape (if calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Shapes:            \n",
      " Param Sites:            \n",
      "Sample Sites:            \n",
      "       a dist       |    \n",
      "        value       |    \n",
      "       b dist       | 2  \n",
      "        value       | 2  \n",
      " c_plate dist       |    \n",
      "        value     2 |    \n",
      "       c dist     2 |    \n",
      "        value     2 |    \n",
      " d_plate dist       |    \n",
      "        value     3 |    \n",
      "       d dist     3 | 4 5\n",
      "        value     3 | 4 5\n",
      "  x_axis dist       |    \n",
      "        value     3 |    \n",
      "  y_axis dist       |    \n",
      "        value     2 |    \n",
      "       x dist   3 1 |    \n",
      "        value   3 1 |    \n",
      "       y dist 2 1 1 |    \n",
      "        value 2 1 1 |    \n",
      "      xy dist 2 3 1 |    \n",
      "        value 2 3 1 |    \n",
      "       z dist 2 3 1 | 5  \n",
      "        value 2 3 1 | 5  \n"
     ]
    }
   ],
   "source": [
    "trace = poutine.trace(model1).get_trace()\n",
    "# trace.compute_log_prob()  # <- optional\n",
    "print(trace.format_shapes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling tensors inside a `plate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main uses of `plate` is to subsample data. Since data are conditionally independent inside a plate, the expected value of loss on e.g. half the data should be half the expected loss on the full data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subsample data, pyro needs to know both the original data size and the subsample size. Pyro then chooses a random subset of data and yield a set of indicies (although this is customizable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.arange(100.)\n",
    "\n",
    "def model2():\n",
    "    mean = pyro.param(\"mean\", torch.zeros(len(data)))\n",
    "    with pyro.plate(\"data\", len(data), subsample_size=10) as ind:\n",
    "        assert len(ind) == 10\n",
    "        batch = data[ind]        \n",
    "        mean_batch = mean[ind]\n",
    "        \n",
    "        # do stuff with the batch\n",
    "        x = pyro.sample(\"x\", Normal(mean_batch, 1), obs=batch)\n",
    "        assert len(x) == 10\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model2, guide=lambda: None, loss=Trace_ELBO())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
